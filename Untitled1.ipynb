{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8212d982-1652-4622-bbe0-6f6ae4e8311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Alta_doc_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    prompt = f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "142e7dac-46fb-42fa-9218-6c51b636eaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import threading\n",
    "import requests\n",
    "import logging\n",
    "from tenacity import retry, wait_fixed, stop_after_attempt, retry_if_exception_type\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Journalisation des erreurs\n",
    "logging.basicConfig(filename='error.log', level=logging.DEBUG, format='%(asctime)s [%(levelname)s] %(message)s')\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    app.logger.info(\"API d√©marr√©e correctement.\")\n",
    "    return 'L‚ÄôAPI fonctionne. Utilise POST sur /document pour envoyer du code.'\n",
    "\n",
    "# Retry pour les appels r√©seau √† Ollama\n",
    "@retry(\n",
    "    retry=retry_if_exception_type((requests.exceptions.RequestException,)),\n",
    "    wait=wait_fixed(2),\n",
    "    stop=stop_after_attempt(3)\n",
    ")\n",
    "def call_llm(full_prompt):\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            \"model\": \"devstral:24b\",\n",
    "            \"prompt\": full_prompt,\n",
    "            \"stream\": False\n",
    "        },\n",
    "        timeout=10\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json().get('response', '')\n",
    "\n",
    "@app.route('/document', methods=['POST'])\n",
    "def document_code():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        code = data.get('code', '').strip()\n",
    "\n",
    "        if not code:\n",
    "            app.logger.warning(\"Aucun code fourni dans la requ√™te POST.\")\n",
    "            return jsonify({'error': 'Aucun code fourni.'}), 400\n",
    "\n",
    "        try:\n",
    "            with open(\"Alta_doc_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "                base_prompt = f.read()\n",
    "        except FileNotFoundError:\n",
    "            app.logger.error(\"Fichier de prompt manquant.\")\n",
    "            return jsonify({'error': 'Fichier de prompt introuvable.'}), 500\n",
    "\n",
    "        full_prompt = f\"{base_prompt}\\n\\n{code}\"\n",
    "        documentation = call_llm(full_prompt)\n",
    "\n",
    "        if not documentation.strip():\n",
    "            app.logger.warning(\"R√©ponse vide du mod√®le.\")\n",
    "            return jsonify({'documentation': '', 'warning': 'R√©ponse vide du LLM'}), 200\n",
    "\n",
    "        return jsonify({'documentation': documentation})\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        app.logger.error(f\"Erreur de connexion √† Ollama : {e}\")\n",
    "        return jsonify({'error': f'Erreur r√©seau ou mod√®le indisponible : {str(e)}'}), 502\n",
    "\n",
    "    except Exception as e:\n",
    "        app.logger.exception(\"Erreur serveur inattendue.\")\n",
    "        return jsonify({'error': f'Erreur serveur : {str(e)}'}), 500\n",
    "\n",
    "@app.errorhandler(404)\n",
    "def not_found(error):\n",
    "    return jsonify({'error': 'Ressource non trouv√©e'}), 404\n",
    "\n",
    "@app.errorhandler(500)\n",
    "def internal_error(error):\n",
    "    return jsonify({'error': 'Erreur interne du serveur'}), 500\n",
    "\n",
    "import nest_asyncio\n",
    "import threading\n",
    "\n",
    "nest_asyncio.apply()  # important pour √©viter le blocage dans Jupyter\n",
    "\n",
    "def run_app():\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "\n",
    "threading.Thread(target=run_app).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cafb0a7-3eb2-43ae-82b6-2fe76e8f2251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API accessible : L‚ÄôAPI fonctionne. Utilise POST sur /document pour envoyer du code.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:5000\")\n",
    "    print(\" API accessible :\", response.text)\n",
    "except Exception as e:\n",
    "    print(\" Erreur d'acc√®s √† l'API :\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7009290-5ac0-43f5-bb43-4e388283ee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Documentation g√©n√©r√©e :\n",
      "‚ùå Aucune documentation g√©n√©r√©e\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "test_code = \"\"\"\n",
    "def greet(name):\n",
    "    return f\"Hello {name}\"\n",
    "\"\"\"\n",
    "\n",
    "response = requests.post(\"http://localhost:5000/document\", json={\"code\": test_code})\n",
    "print(\"üìÑ Documentation g√©n√©r√©e :\")\n",
    "print(response.json().get(\"documentation\", \"‚ùå Aucune documentation g√©n√©r√©e\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2ff4fe-2485-4c45-86b0-b758dc8aa5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier 'train_tuning.py' enregistr√© avec succ√®s.\n"
     ]
    }
   ],
   "source": [
    "code_content = \"\"\"\n",
    "# script for training the model\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ROOT = Path(os.path.abspath(__file__)).parents[2]\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "from src.unet.dataset.dataset import SegrailsDataset\n",
    "from src.unet.model.losses import Loss\n",
    "from src.unet.model.optimizers import Optimizer, Scheduler\n",
    "from src.unet.model.unet import Unet\n",
    "from src.unet.trainer.trainer import Trainer\n",
    "from src.unet.utils.parameters import train_parameters\n",
    "from src.unet.utils.strings import dict2print, get_logger\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train_data\", type=str, help=\"path to train data\")\n",
    "    parser.add_argument(\"--val_data\", type=str, help=\"path to validation data\")\n",
    "    parser.add_argument(\"--log_dir\", type=str, default=\"../../runs\", help=\"path to log\")\n",
    "    parser.add_argument(\"--loss\", type=str, help=\"loss function\")\n",
    "    parser.add_argument(\"--optimizer\", type=str, help=\"optimizer function\")\n",
    "    parser.add_argument(\"--lr\", type=float, help=\"learning rate\")\n",
    "    parser.add_argument(\"--weight_decay\", type=str, help=\"weight decay\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    tuning_parameters = {\n",
    "        \"loss\": str(args.loss),\n",
    "        \"optimizer\": {\n",
    "            \"method\": str(args.optimizer),\n",
    "            \"lr\": float(args.lr),\n",
    "            \"momentum\": 0.8,\n",
    "            \"weight_decay\": float(args.weight_decay),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    config = train_parameters()\n",
    "    model_params = config[\"model\"]\n",
    "    train_params = config[\"train\"]\n",
    "    eval_params = config[\"evaluate\"]\n",
    "    train_params.update(tuning_parameters)\n",
    "\n",
    "    if not os.path.exists(args.log_dir):\n",
    "        os.mkdir(args.log_dir)\n",
    "    log_filename = os.path.join(args.log_dir, \"train.log\")\n",
    "    logger = get_logger(log_filename, \"trainer\", True)\n",
    "    logger.info(\"\\\\nNew Experiment\\\\n\")\n",
    "\n",
    "    model = Unet(**model_params)\n",
    "    logger.info(\"Successfully created the model with the following parameters:\")\n",
    "    logger.info(dict2print(model_params))\n",
    "    logger.info(f\"Training on {train_params['epochs']} epochs\")\n",
    "\n",
    "    checkpoint_file = os.path.join(args.log_dir, \"best.pt\")\n",
    "\n",
    "    im_size = train_params[\"image_size\"]\n",
    "    logger.info(f\"Images are resized to {str(im_size)}\")\n",
    "    transforms = v2.Compose([v2.RandomCrop(size=im_size)])\n",
    "    train_dataset = SegrailsDataset(args.train_data, transforms=transforms)\n",
    "    val_dataset = SegrailsDataset(args.val_data, transforms=transforms)\n",
    "    logger.info(f\"Loaded the train dataset: {len(train_dataset)} images\")\n",
    "    logger.info(f\"Loaded the validation dataset: {len(val_dataset)} images\")\n",
    "    logger.info(\"\\\\n\")\n",
    "\n",
    "    optimizer = Optimizer(**train_params[\"optimizer\"]).attach(model)\n",
    "    scheduler = Scheduler(**train_params[\"scheduler\"]).attach(optimizer)\n",
    "    loss_fn = Loss(train_params[\"loss\"], True).func()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        logger,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        model,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        train_params,\n",
    "        eval_params,\n",
    "        checkpoint_file,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\"\"\"\n",
    "\n",
    "with open(\"train_tuning.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(code_content)\n",
    "\n",
    "print(\"‚úÖ Fichier 'train_tuning.py' enregistr√© avec succ√®s.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc5f8301-28ee-4d26-b71a-3f97649a05ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucune documentation n'a √©t√© g√©n√©r√©e. V√©rifie si le mod√®le a bien r√©pondu.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Lire le contenu du fichier √† documenter\n",
    "with open(\"train_tuning.py\", \"r\", encoding=\"utf-8\") as f:\n",
    "    file_code = f.read()\n",
    "\n",
    "# Envoyer le code √† l'API Flask\n",
    "response = requests.post(\n",
    "    \"http://localhost:5000/document\",\n",
    "    json={\"code\": file_code}\n",
    ")\n",
    "\n",
    "# V√©rifier et afficher la documentation re√ßue\n",
    "response_data = response.json()\n",
    "if \"documentation\" in response_data:\n",
    "    print(\"Documentation g√©n√©r√©e :\")\n",
    "    print(response_data[\"documentation\"])\n",
    "else:\n",
    "    print(\"Aucune documentation n'a √©t√© g√©n√©r√©e. V√©rifie si le mod√®le a bien r√©pondu.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa97c8-e036-4961-8a7e-9074a7d4f415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (devstral_env)",
   "language": "python",
   "name": "devstral_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
